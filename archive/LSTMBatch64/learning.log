
###########################################################
######### Loading Data
###########################################################

Parsing Data uni
READ DATA FROM CACHE
READ GROUND TRUTH DATA FROM CACHE
Parsing Data tutoring0
READ DATA FROM CACHE
READ GROUND TRUTH DATA FROM CACHE
Parsing Data uni2
READ DATA FROM CACHE
READ GROUND TRUTH DATA FROM CACHE
Parsing Data dog0
READ DATA FROM CACHE
READ GROUND TRUTH DATA FROM CACHE
Parsing Data uni3
READ DATA FROM CACHE
READ GROUND TRUTH DATA FROM CACHE
Parsing Data train0
READ DATA FROM CACHE
READ GROUND TRUTH DATA FROM CACHE
Parsing Data mb0
READ DATA FROM CACHE
READ GROUND TRUTH DATA FROM CACHE
Parsing Data uni1
READ DATA FROM CACHE
READ GROUND TRUTH DATA FROM CACHE

###########################################################
######### Hyper-Parameters
###########################################################

Sequence Length:  300
Sequence Offset:  30

###########################################################
######### Training Data
###########################################################

Training Activities:  6
['uni', 'tutoring0', 'uni2', 'dog0', 'uni3', 'train0']
Number of Testing Activities:  2
['mb0', 'uni1']

###########################################################
######### Training Sequences and Batches
###########################################################

Training Data Consists of  21022  Unique Sequences of Length  300
Testing Data Consists of   6364  Unique Sequences of Length  300

Training Batch Size:  64
Batches per Epoch:  329

###########################################################
######### Validation Data
###########################################################


Number of Validation Sequences:  2863

###########################################################
######### Model
###########################################################

_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm (LSTM)                  (None, None, 128)         72192     
_________________________________________________________________
lstm_1 (LSTM)                (None, None, 128)         131584    
_________________________________________________________________
lstm_2 (LSTM)                (None, None, 128)         131584    
_________________________________________________________________
lstm_3 (LSTM)                (None, None, 128)         131584    
_________________________________________________________________
lstm_4 (LSTM)                (None, None, 128)         131584    
_________________________________________________________________
lstm_5 (LSTM)                (None, None, 128)         131584    
_________________________________________________________________
dense (Dense)                (None, None, 2)           258       
=================================================================
Total params: 730,370
Trainable params: 730,370
Non-trainable params: 0
_________________________________________________________________
Epoch 1/40
[2K[2K - 841s - loss: 8.9311 - val_loss: 1.8339
Epoch 2/40
[2K[2K - 822s - loss: 2.5765 - val_loss: 1.3501
Epoch 3/40
[2K[2K - 831s - loss: 1.8927 - val_loss: 0.8243
Epoch 4/40
[2K[2K - 838s - loss: 1.6779 - val_loss: 0.9391
Epoch 5/40
[2K[2K
Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.
 - 832s - loss: 1.7379 - val_loss: 1.3865
Epoch 6/40
[2K[2K - 824s - loss: 0.4133 - val_loss: 0.4151
Epoch 7/40
[2K[2K - 817s - loss: 0.3266 - val_loss: 0.4099
Epoch 8/40
[2K[2K - 826s - loss: 0.3085 - val_loss: 0.3813
Epoch 9/40
[2K[2K - 837s - loss: 0.2981 - val_loss: 0.4200
Epoch 10/40
[2K[2K - 825s - loss: 0.2927 - val_loss: 0.3776
Epoch 11/40
[2K[2K - 825s - loss: 0.2922 - val_loss: 0.3577
Epoch 12/40
[2K[2K - 837s - loss: 0.2800 - val_loss: 0.3379
Epoch 13/40
[2K[2K - 826s - loss: 0.2728 - val_loss: 0.3033
Epoch 14/40
[2K[2K - 826s - loss: 0.2892 - val_loss: 0.3364
Epoch 15/40
[2K[2K
Epoch 00015: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.
 - 826s - loss: 0.2907 - val_loss: 0.3919
Epoch 16/40
[2K[2K - 829s - loss: 0.2281 - val_loss: 0.3134
Epoch 17/40
[2K[2K
Epoch 00017: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.
 - 828s - loss: 0.2236 - val_loss: 0.3175
Epoch 00017: early stopping

###########################################################
######### Testing Data
###########################################################

Test Data
1/1 [==============================] - 152s 152s/step
loss (test-set): 0.6825186014175415
Test Data
1/1 [==============================] - 200s 200s/step
loss (test-set): 1.2863059043884277
Plotting  mb0
Accuracy of GPS:  8.118735040550984
Accuracy of RNN:  13.523922695970922
Plotting  uni1
Accuracy of GPS:  14.19821065975769
Accuracy of RNN:  15.798463705706219
Plotting  uni
Accuracy of GPS:  4.244203826619129
Accuracy of RNN:  9.749376848920228
Plotting  tutoring0
Accuracy of GPS:  4.147782885750094
Accuracy of RNN:  4.448453847283752
Plotting  uni2
Accuracy of GPS:  7.065320232180366
Accuracy of RNN:  8.435867361002154
Plotting  dog0
Accuracy of GPS:  4.024814488360335
Accuracy of RNN:  4.694229694577591
Plotting  uni3
Accuracy of GPS:  18.392328962502493
Accuracy of RNN:  12.34110410553812
Plotting  train0
